import psycopg2
import json
import os
import torch
from sentence_transformers import SentenceTransformer
from psycopg2.extras import execute_values
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================
# 1. C·∫•u h√¨nh
# ============================
# C·∫•u h√¨nh DB (S·ª≠ d·ª•ng localhost cho ch·∫°y tr√™n m√°y Host, ho·∫∑c host.docker.internal n·∫øu ch·∫°y trong container)
DB_CONFIG = {
    "dbname": "news",
    "user": "chison", 
    "password": "caosychison13",
    # >>> D√πng "localhost" n·∫øu b·∫°n ƒëang ch·∫°y file n√†y ngo√†i Docker Container
    "host": "localhost", 
    "port": "6969"
}

# ƒê∆∞·ªùng d·∫´n ƒë√£ l∆∞u m√¥ h√¨nh SimCSE PhoBERT (ƒê·∫£m b·∫£o tr√πng v·ªõi SAVE_PATH trong file t·∫£i model)
LOAD_PATH = "./models/ModelPhoberSim" 
# ============================
# 2. H√†m T·∫£i D·ªØ li·ªáu Topic t·ª´ DB
# ============================

def load_topics_from_db():
    """T·∫£i topic_id, t√™n v√† m√¥ t·∫£ t·ª´ b·∫£ng topics."""
    conn = None
    topics_data = []
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        # Truy v·∫•n c√°c c·ªôt c·∫ßn thi·∫øt t·ª´ b·∫£ng topics
        sql = """
        SELECT topic_id, name, short_description, long_description, example
        FROM topic
        ORDER BY topic_id;
        """
        cur.execute(sql)
        
        for row in cur.fetchall():
            topic_id, name, short_description, long_description, examples_json = row
            
            # X·ª≠ l√Ω c·ªôt JSONB 'examples'
            try:
                # N·∫øu psycopg2 kh√¥ng t·ª± chuy·ªÉn ƒë·ªïi JSONB th√†nh list, ph·∫£i d√πng json.loads
                examples = examples_json if isinstance(examples_json, list) else json.loads(examples_json)
            except (TypeError, json.JSONDecodeError):
                examples = []

            topics_data.append({
                "topic_id": topic_id,
                "name": name,
                "short_description": short_description,
                "long_description": long_description,
                "example": examples
            })
            
        cur.close()
        return topics_data
        
    except Exception as e:
        logger.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu Topic t·ª´ DB: {e}")
        return []
    finally:
        if conn:
            conn.close()

def topic_to_text(topic):
    """K·∫øt h·ª£p c√°c tr∆∞·ªùng c·ªßa Topic th√†nh m·ªôt chu·ªói duy nh·∫•t ƒë·ªÉ embedding."""
    examples_text = " ".join(topic.get("example", []))
    return (
        f"{topic.get('name','')}. "
        f"{topic.get('short_description','')} "
        f"{topic.get('long_description','')} "
        f"{examples_text}"
    )

# ============================
# 3. H√†m Import Embeddings v√†o DB
# ============================

def insert_embeddings(topic_ids, topic_embeddings):
    """Ch√®n topic_id v√† vector v√†o b·∫£ng topic_embedding."""
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        # T·∫°o danh s√°ch c√°c tuple (topic_id, vector_string)
        rows = []
        for topic_id, embedding in zip(topic_ids, topic_embeddings.tolist()):
            # Chuy·ªÉn list Python th√†nh chu·ªói vector e.g., "[0.123, -0.456, ...]" cho ki·ªÉu VECTOR
            vector_str = '[' + ','.join(map(str, embedding)) + ']'
            rows.append((topic_id, vector_str))

        sql = """
        INSERT INTO topic_embedding (topic_id, embedding)
        VALUES %s
        ON CONFLICT (topic_id) DO UPDATE 
        SET embedding = EXCLUDED.embedding;
        """
        execute_values(cur, sql, rows)
        conn.commit()
        logger.info(f"üì• ƒê√£ ch√®n/c·∫≠p nh·∫≠t {len(rows)} embeddings v√†o DB.")
        
    except Exception as e:
        logger.error(f"L·ªói khi ch√®n embeddings v√†o DB: {e}")
    finally:
        if conn:
            conn.close()

# ============================
# 4. Main Execution
# ============================


if not os.path.isdir(LOAD_PATH):
    logger.error(f"‚õîÔ∏è L·ªói: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c model t·∫°i {LOAD_PATH}. H√£y ch·∫°y l·∫°i file t·∫£i model tr∆∞·ªõc.")
    exit()

# B∆∞·ªõc 1: T·∫£i d·ªØ li·ªáu Topic
topics_data = load_topics_from_db()
if not topics_data:
    logger.warning("Kh√¥ng c√≥ d·ªØ li·ªáu Topic ƒë·ªÉ x·ª≠ l√Ω.")
    exit()

topic_texts = [topic_to_text(t) for t in topics_data]
topic_ids = [t['topic_id'] for t in topics_data]
logger.info(f"ƒê√£ t·∫£i {len(topic_texts)} vƒÉn b·∫£n Topic t·ª´ DB.")

# B∆∞·ªõc 2: T√≠nh to√°n Embeddings
try:
    # T·∫£i m√¥ h√¨nh t·ª´ th∆∞ m·ª•c c·ª•c b·ªô ƒë√£ l∆∞u
    model = SentenceTransformer(LOAD_PATH)
    logger.info("‚úÖ Model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng t·ª´ th∆∞ m·ª•c c·ª•c b·ªô.")
    
    # Encode t·∫•t c·∫£ topic texts
    topic_embeddings = model.encode(topic_texts, convert_to_tensor=True)
    logger.info(f"ƒê√£ t·∫°o embeddings v·ªõi shape: {topic_embeddings.shape}")

    # B∆∞·ªõc 3: Import Embeddings v√†o DB
    insert_embeddings(topic_ids, topic_embeddings)
    
except Exception as e:
    logger.error(f"‚õîÔ∏è L·ªói trong qu√° tr√¨nh Embedding ho·∫∑c Import: {e}")